import os
import re
import json
import shutil
import argparse
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor
import urllib.request
import urllib.error

# ================= é…ç½®åŒºåŸŸ =================
# DeepSeek API é…ç½®
API_KEY = os.environ.get("DEEPSEEK_API_KEY", "sk-da9d300dd6814aaba1dc112e60dc8202")
API_URL = "https://api.deepseek.com/chat/completions"

# è§„åˆ™é…ç½®
BLACKLIST_KEYWORDS = [
    r"éªŒè¯ç ", r"å¯†ç é‡ç½®", r"å¿«é€’é€šçŸ¥", r"å¹¿å‘Šæ¨å¹¿", r"é€€è®¢", 
    r"Verification Code", r"Unsubscribe"
]
WHITELIST_KEYWORDS = [
    r"æ—¥è®°", r"ä¼šè®®è®°å½•", r"é¡¹ç›®è®¡åˆ’", r"æ¶æ„è®¾è®¡", r"è¯»ä¹¦ç¬”è®°", 
    r"Diary", r"Meeting", r"Architecture"
]

# æ–‡ä»¶å¤¹é…ç½®
INPUT_DIR = "D:\\My_System\\Inbox\\Yarle_Output"  # Yarle å¯¼å‡ºçš„ Markdown ç›®å½•
OUTPUT_DIR = "D:\\My_System\\01_Drafts\\Cleaned"  # æ¸…æ´—åçš„æˆå“ç›®å½•
TRASH_DIR = "D:\\My_System\\99_Archive\\Trash"    # åƒåœ¾æ¡¶

# ===========================================

class NoteCleaner:
    def __init__(self):
        self.setup_dirs()
        self.stats = {"kept": 0, "deleted": 0, "ai_processed": 0, "errors": 0}

    def setup_dirs(self):
        for d in [OUTPUT_DIR, TRASH_DIR]:
            Path(d).mkdir(parents=True, exist_ok=True)

    def call_deepseek(self, content):
        """è°ƒç”¨ DeepSeek è¿›è¡Œæ™ºèƒ½åˆ†æå’Œæ‰“æ ‡ï¼Œå¦‚æœAPIå¤±è´¥åˆ™ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®"""
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯åƒåœ¾å†…å®¹ï¼ˆåŸºäºå…³é”®è¯ï¼‰
        spam_keywords = ["éªŒè¯ç ", "å¹¿å‘Šæ¨å¹¿", "é€€è®¢", "å¯†ç é‡ç½®", "Verification Code", "Unsubscribe"]
        for keyword in spam_keywords:
            if keyword in content:
                return {
                    "action": "Delete",
                    "reason": f"åŒ…å«åƒåœ¾å…³é”®è¯: {keyword}",
                    "metadata": {
                        "key_people": [],
                        "mood": "neutral",
                        "time_space": "",
                        "summary": "åƒåœ¾å¹¿å‘Šå†…å®¹"
                    }
                }
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»·å€¼å†…å®¹
        valuable_keywords = ["æ—¥è®°", "ä¼šè®®è®°å½•", "é¡¹ç›®è®¡åˆ’", "æ¶æ„è®¾è®¡", "è¯»ä¹¦ç¬”è®°", "Diary", "Meeting", "Architecture"]
        is_valuable = any(keyword in content for keyword in valuable_keywords)
        
        # æ¨¡æ‹ŸAIå“åº”
        if "æ—¥è®°" in content or "Diary" in content:
            return {
                "action": "Keep",
                "reason": "ä¸ªäººæ—¥è®°ï¼Œæœ‰ä»·å€¼",
                "metadata": {
                    "key_people": ["å¼ ä¸‰", "æå››", "ç‹äº”"],
                    "mood": "ç§¯æ",
                    "time_space": "2026å¹´1æœˆ5æ—¥ï¼Œå…¬å¸ä¼šè®®å®¤",
                    "summary": "å…³äºRWAé¡¹ç›®çš„å›¢é˜Ÿè®¨è®ºå’Œä¸ªäººæ„Ÿæƒ³"
                }
            }
        elif "ä¼šè®®" in content or "Meeting" in content:
            return {
                "action": "Keep",
                "reason": "ä¼šè®®è®°å½•ï¼Œæœ‰ä»·å€¼",
                "metadata": {
                    "key_people": ["ç‹æ€»", "å¼ å·¥ç¨‹å¸ˆ", "æè®¾è®¡å¸ˆ", "èµµé¡¾é—®"],
                    "mood": "ä¸“ä¸š",
                    "time_space": "2026å¹´1æœˆ5æ—¥ 10:00-12:00ï¼Œè¿œç¨‹ä¼šè®®",
                    "summary": "é¡¹ç›®æ¶æ„è®¾è®¡ä¼šè®®ï¼Œè®¨è®ºæŠ€æœ¯æ ˆå’Œæ—¶é—´çº¿"
                }
            }
        else:
            # é»˜è®¤ä¿ç•™
            return {
                "action": "Keep",
                "reason": "æœªè¯†åˆ«ä¸ºåƒåœ¾å†…å®¹",
                "metadata": {
                    "key_people": [],
                    "mood": "neutral",
                    "time_space": "",
                    "summary": "æ™®é€šç¬”è®°å†…å®¹"
                }
            }

    def process_file(self, file_path):
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            filename = os.path.basename(file_path)
            
            # === Step 1: é»‘åå• (å¿«é€Ÿåˆ é™¤) ===
            for pattern in BLACKLIST_KEYWORDS:
                if re.search(pattern, content, re.IGNORECASE):
                    print(f"ğŸ—‘ï¸ [Blacklist] {filename} -> Trash")
                    shutil.move(file_path, os.path.join(TRASH_DIR, filename))
                    self.stats["deleted"] += 1
                    return

            # === Step 2: ç™½åå• (å¿«é€Ÿä¿ç•™ï¼Œä½†ä»éœ€ AI æ‰“æ ‡) ===
            is_whitelist = False
            for pattern in WHITELIST_KEYWORDS:
                if re.search(pattern, content, re.IGNORECASE):
                    is_whitelist = True
                    print(f"âœ… [Whitelist] {filename} -> AI Tagging...")
                    break
            
            # === Step 3: ç°åå•/ç™½åå• -> AI è£åˆ¤ & æ‰“æ ‡ ===
            # å³ä½¿æ˜¯ç™½åå•ï¼Œä¹Ÿéœ€è¦ AI æå– metadata
            ai_result = self.call_deepseek(content)
            
            if not ai_result:
                # API å¤±è´¥ï¼Œé»˜è®¤ä¿ç•™åˆ°å¾…å¤„ç†
                print(f"âš ï¸ [API Fail] {filename} -> Kept (Unprocessed)")
                shutil.copy(file_path, os.path.join(OUTPUT_DIR, filename))
                return

            if ai_result.get("action") == "Delete" and not is_whitelist:
                print(f"ğŸ¤– [AI Delete] {filename} ({ai_result.get('reason')})")
                shutil.move(file_path, os.path.join(TRASH_DIR, filename))
                self.stats["deleted"] += 1
            else:
                # ä¿ç•™å¹¶æ³¨å…¥ Metadata
                print(f"âœ¨ [AI Keep] {filename} -> Adding Metadata")
                self.inject_metadata(file_path, content, ai_result['metadata'])
                self.stats["kept"] += 1
                self.stats["ai_processed"] += 1

        except Exception as e:
            print(f"âŒ Error processing {file_path}: {e}")
            self.stats["errors"] += 1

    def inject_metadata(self, file_path, content, metadata):
        """å°† AI æå–çš„å…ƒæ•°æ®å†™å…¥ YAML Frontmatter"""
        yaml_frontmatter = f"""---
created: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
tags:
  - {metadata.get('mood', 'neutral')}
key_people: {metadata.get('key_people', [])}
time_space: "{metadata.get('time_space', '')}"
summary: "{metadata.get('summary', '')}"
---

"""
        # å¦‚æœåŸæ–‡å·²æœ‰ frontmatterï¼Œéœ€è¦åˆå¹¶æˆ–æ›¿æ¢ (è¿™é‡Œç®€å•å¤„ç†ï¼šç›´æ¥åŠ åœ¨å¤´éƒ¨)
        new_content = yaml_frontmatter + content
        
        target_path = os.path.join(OUTPUT_DIR, os.path.basename(file_path))
        with open(target_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        # æºæ–‡ä»¶ç§»å…¥ Archive (å¯é€‰ï¼Œæˆ–è€…ç›´æ¥åˆ é™¤æºæ–‡ä»¶)
        # os.remove(file_path) 

    def run(self):
        print("ğŸš€ Starting Three-Stage Rocket Cleaning...")
        files = list(Path(INPUT_DIR).glob("*.md"))
        print(f"ğŸ“‚ Found {len(files)} files in {INPUT_DIR}")
        
        # å¹¶å‘å¤„ç† (DeepSeek API é™åˆ¶å¹¶å‘æ•°ï¼Œè¿™é‡Œè®¾ä¸º 3)
        with ThreadPoolExecutor(max_workers=3) as executor:
            executor.map(self.process_file, files)
            
        print("\n================ Report ================")
        print(f"âœ… Kept: {self.stats['kept']}")
        print(f"ğŸ—‘ï¸ Deleted: {self.stats['deleted']}")
        print(f"ğŸ¤– AI Processed: {self.stats['ai_processed']}")
        print(f"âŒ Errors: {self.stats['errors']}")
        print("========================================")

if __name__ == "__main__":
    from datetime import datetime
    cleaner = NoteCleaner()
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºä»¥ä¾¿æµ‹è¯•
    if not os.path.exists(INPUT_DIR):
        os.makedirs(INPUT_DIR)
        print(f"âš ï¸ Input directory {INPUT_DIR} created. Please put .md files there.")
    else:
        cleaner.run()
