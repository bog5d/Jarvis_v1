import streamlit as st
import time
import yaml
from pathlib import Path
from datetime import datetime
import sys

# Add src to path
sys.path.append(str(Path(__file__).parent.parent))
from src.chat_engine import JarvisChat
from src.handlers.audio_handler import AudioHandler

st.set_page_config(
    page_title="Jarvis Command Center",
    page_icon="ğŸ§ ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- Styles ---
st.markdown("""
<style>
    /* ç§»é™¤é¡¶éƒ¨å¤šä½™ç©ºç™½ï¼Œè®©å¸ƒå±€æ›´ç´§å‡‘ */
    .block-container {
        padding-top: 2rem;
    }
    
    /* Tabs å®¹å™¨ - æ›´åŠ æ¸…çˆ½çš„åº•éƒ¨çº¿æ¡ */
    .stTabs [data-baseweb="tab-list"] {
        gap: 30px;
        border-bottom: 1px solid #f0f2f6;
        padding-bottom: 5px;
    }

    /* å•ä¸ª Tab - ç§»é™¤é»‘è‰²èƒŒæ™¯ï¼Œæ”¹ä¸ºé€æ˜ï¼Œæç®€é£æ ¼ */
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: transparent;
        border-radius: 0px;
        gap: 5px;
        padding-top: 10px;
        padding-bottom: 10px;
        color: #666; /* æŸ”å’Œçš„ç°è‰² */
        font-weight: 500;
        font-size: 16px;
        border: none;
        transition: all 0.3s ease;
    }

    /* é€‰ä¸­çŠ¶æ€ - åªæœ‰åº•éƒ¨é«˜äº®ï¼Œæ–‡å­—å˜é»‘ */
    .stTabs [aria-selected="true"] {
        background-color: transparent;
        color: #000;
        font-weight: 600;
        border-bottom: 3px solid #FF4B4B; /* ä½¿ç”¨é†’ç›®çš„çº¢è‰²çº¿æ¡ */
    }
    
    /* æ‚¬åœçŠ¶æ€ */
    .stTabs [data-baseweb="tab"]:hover {
        color: #FF4B4B;
        background-color: transparent;
    }

    /* ä¼˜åŒ– Metric æ˜¾ç¤ºï¼Œå¢åŠ è½»å¾®å¡ç‰‡æ„Ÿï¼Œé€‚é…ç™½è‰²èƒŒæ™¯ */
    div[data-testid="stMetric"] {
        background-color: #ffffff;
        padding: 15px 20px;
        border-radius: 8px;
        box-shadow: 0 1px 3px rgba(0,0,0,0.08); /* è½»å¾®é˜´å½± */
        border: 1px solid #f0f2f6;
    }
</style>
""", unsafe_allow_html=True)

# --- Init Jarvis ---
if "jarvis" not in st.session_state:
    config_path = Path(__file__).parent.parent / "config" / "settings.yaml"
    
    # Load Config
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
        
    st.session_state.jarvis = JarvisChat(str(config_path))
    st.session_state.jarvis.initialize_context()
    
    # Init AudioHandler for Voice Chat
    st.session_state.audio_handler = AudioHandler(
        output_dir=config['paths']['output_dir'],
        api_key=config['aliyun']['api_key']
    )

if "last_check_time" not in st.session_state:
    st.session_state.last_check_time = time.time()

def check_for_new_drafts():
    """æ£€æŸ¥æ˜¯å¦æœ‰æ–°å¤„ç†å®Œæˆçš„å¥æŠ˜ (Drafts)"""
    drafts_dir = Path("D:/My_System/01_Drafts")
    if not drafts_dir.exists(): return

    # æŸ¥æ‰¾è‡ªä¸Šæ¬¡æ£€æŸ¥ä»¥æ¥æ–°ä¿®æ”¹/ç”Ÿæˆçš„æ–‡ä»¶
    new_files = []
    for f in drafts_dir.glob("*.md"):
        if "æ¯æ—¥å†…é˜æ™¨æŠ¥" in f.name: continue
        if f.stat().st_mtime > st.session_state.last_check_time:
            new_files.append(f)
    
    if new_files:
        for f in new_files:
            try:
                content = f.read_text(encoding='utf-8')
                # æ„é€ é€šçŸ¥æ¶ˆæ¯
                msg = f"âœ… **ã€ç³»ç»Ÿé€šçŸ¥ã€‘åå°å·²å®Œæˆæ–‡ä»¶å¤„ç†**\n\nğŸ“„ **æ–‡ä»¶**: `{f.name}`\n\n**æ‘˜è¦å†…å®¹**:\n{content[:500]}...\n\n(å·²å­˜å…¥è®°å¿†åº“ï¼Œæ‚¨ç°åœ¨å¯ä»¥å°±æ­¤æé—®)"
                st.session_state.jarvis.messages.append({"role": "assistant", "content": msg})
            except Exception:
                pass
        # æ›´æ–°æ£€æŸ¥æ—¶é—´
        st.session_state.last_check_time = time.time()

# æ¯æ¬¡é¡µé¢åˆ·æ–°/äº¤äº’æ—¶ï¼Œéƒ½æ£€æŸ¥ä¸€æ¬¡
check_for_new_drafts()

# --- Sidebar: Auto-Refresh ---
with st.sidebar:
    st.title("âš™ï¸ æ§åˆ¶å°è®¾ç½®")
    auto_refresh = st.toggle("ğŸ”´ å®æ—¶ç›‘æ§æ¨¡å¼", value=False, help="å¼€å¯åæ¯ 5 ç§’è‡ªåŠ¨åˆ·æ–°é¡µé¢ï¼Œä»¥ä¾¿å³æ—¶æ¥æ”¶åå°å¤„ç†å®Œæˆçš„é€šçŸ¥ã€‚æ³¨æ„ï¼šæ‰“å­—æ—¶å»ºè®®å…³é—­ï¼Œä»¥å…æ‰“æ–­è¾“å…¥ã€‚")
    
    if st.button("ğŸ”„ æ‰‹åŠ¨åˆ·æ–°"):
        st.rerun()

if auto_refresh:
    time.sleep(5)
    st.rerun()

# --- Tabs ---
tab1, tab2 = st.tabs(["ğŸ“Š ç›‘æ§å¤§å± (Monitor)", "ğŸ’¬ é¡¾é—®å¯¹è¯ (Chat)"])

# === Tab 1: Monitor ===
with tab1:
    st.title("ğŸ“Š Jarvis System Monitor")
    
    # Metrics
    col1, col2, col3 = st.columns(3)
    
    drafts_dir = Path("D:/My_System/01_Drafts")
    briefing_dir = Path("D:/My_System/02_Briefings")
    
    # Count today's drafts
    today_drafts = 0
    one_day_ago = time.time() - 24 * 3600
    if drafts_dir.exists():
        today_drafts = sum(1 for f in drafts_dir.glob("*.md") if f.stat().st_mtime > one_day_ago and "æ¯æ—¥å†…é˜æ™¨æŠ¥" not in f.name)
    
    # Last briefing time
    last_briefing = "æ— "
    if briefing_dir.exists():
        briefings = list(briefing_dir.glob("ğŸ“…_æ¯æ—¥å†…é˜æ™¨æŠ¥_*.md"))
        if briefings:
            latest = max(briefings, key=lambda p: p.stat().st_mtime)
            last_briefing = latest.name.replace("ğŸ“…_æ¯æ—¥å†…é˜æ™¨æŠ¥_", "").replace(".md", "")
            briefing_content = latest.read_text(encoding='utf-8')
        else:
            briefing_content = "æš‚æ— ä»Šæ—¥æ™¨æŠ¥"
    else:
        briefing_content = "ç›®å½•ä¸å­˜åœ¨"

    with col1:
        st.metric("ä»Šæ—¥å¥æŠ˜ (24h)", f"{today_drafts} ä»½")
    with col2:
        st.metric("æœ€æ–°æ™¨æŠ¥æ—¥æœŸ", last_briefing)
    with col3:
        st.metric("ç³»ç»ŸçŠ¶æ€", "ğŸŸ¢ Online")

    st.divider()
    
    st.subheader("ğŸ“… æœ€æ–°å†…é˜æ™¨æŠ¥")
    st.markdown(briefing_content)

# === Tab 2: Chat ===
with tab2:
    st.title("ğŸ’¬ å†…é˜é¦–è¾… (DeepSeek)")

    # --- File Uploader ---
    with st.expander("ğŸ“ ä¸Šä¼ å¥æŠ˜ (PDF/Audio/Text)", expanded=False):
        uploaded_file = st.file_uploader("é€‰æ‹©æ–‡ä»¶ä¸Šä¼ è‡³ Inbox", type=['pdf', 'txt', 'md', 'mp3', 'wav', 'm4a'])
        if uploaded_file is not None:
            inbox_dir = Path("D:/My_System/Inbox")
            inbox_dir.mkdir(parents=True, exist_ok=True)
            save_path = inbox_dir / uploaded_file.name
            
            try:
                with open(save_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                st.success(f"âœ… å·²å‘ˆé€’å¥æŠ˜: {uploaded_file.name}ï¼Œå†…é˜æ­£åœ¨å¤„ç†ä¸­...")
                
                # --- å…³é”®ä¿®æ”¹ï¼šç«‹å³è¯»å–æ–‡ä»¶å†…å®¹å¹¶æ³¨å…¥å¯¹è¯ä¸Šä¸‹æ–‡ ---
                file_content = ""
                if uploaded_file.type == "text/plain" or uploaded_file.name.endswith(".md") or uploaded_file.name.endswith(".txt"):
                    # æ–‡æœ¬æ–‡ä»¶ç›´æ¥è¯»å–
                    uploaded_file.seek(0)
                    file_content = uploaded_file.read().decode("utf-8")
                elif uploaded_file.type == "application/pdf":
                    # PDF ç®€å•æå– (éœ€è¦å®‰è£… pypdfï¼Œè¿™é‡Œåšä¸ªç®€å•çš„æç¤ºï¼Œæˆ–è€…å°è¯•è¯»å–)
                    # ä¸ºäº†ç¨³å®šæ€§ï¼Œæš‚æ—¶åªæç¤ºç”¨æˆ·æ–‡ä»¶å·²ä¸Šä¼ ï¼Œç­‰å¾…åå°å¤„ç†
                    file_content = "(PDFæ–‡ä»¶å·²ä¸Šä¼ ï¼Œåå°æ­£åœ¨è½¬å½•ä¸­... è¯·ç¨åè¯¢é—®)"
                else:
                    file_content = "(éŸ³é¢‘/äºŒè¿›åˆ¶æ–‡ä»¶å·²ä¸Šä¼ ï¼Œåå°æ­£åœ¨è½¬å½•ä¸­...)"

                if file_content and len(file_content) < 50000: # é™åˆ¶é•¿åº¦é˜²æ­¢çˆ†Token
                     st.session_state.jarvis.messages.append({
                        "role": "system", 
                        "content": f"ã€ç³»ç»Ÿé€šçŸ¥ã€‘ç”¨æˆ·åˆšåˆšä¸Šä¼ äº†ä¸€ä»½æ–‡ä»¶ã€Š{uploaded_file.name}ã€‹ã€‚\nå¦‚æœè¿™æ˜¯æ–‡æœ¬ï¼Œå†…å®¹å¦‚ä¸‹ï¼š\n{file_content}\n\nå¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œè¯·å‘ŠçŸ¥ç”¨æˆ·åå°æ­£åœ¨å¤„ç†ã€‚"
                    })
                
            except Exception as e:
                st.error(f"âŒ ä¸Šä¼ å¤±è´¥: {e}")

    # Display chat history
    # Filter out system prompts for display
    for msg in st.session_state.jarvis.messages:
        if msg["role"] != "system":
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])

    # --- Input Area ---
    # 1. Audio Input
    audio_value = st.audio_input("ğŸ¤ è¯­éŸ³è¾“å…¥ (Voice Input)")
    
    # 2. Text Input
    text_prompt = st.chat_input("è¯·ä¸‹è¾¾æŒ‡ä»¤æˆ–è¯¢é—®...")
    
    final_prompt = None
    
    # Handle Text Input
    if text_prompt:
        final_prompt = text_prompt
        
    # Handle Audio Input
    elif audio_value:
        # Use hash to prevent re-processing the same audio on rerun
        audio_id = hash(audio_value.getvalue())
        if "last_audio_id" not in st.session_state or st.session_state.last_audio_id != audio_id:
            st.session_state.last_audio_id = audio_id
            
            # Save and Transcribe
            temp_audio_path = Path("temp_voice_input.wav")
            with open(temp_audio_path, "wb") as f:
                f.write(audio_value.getvalue())
            
            with st.spinner("ğŸ‘‚ æ­£åœ¨å¬å–æ‚¨çš„æŒ‡ä»¤..."):
                transcribed_text = st.session_state.audio_handler.transcribe_audio(str(temp_audio_path))
            
            if transcribed_text:
                final_prompt = transcribed_text
                st.toast(f"ğŸ—£ï¸ è¯†åˆ«å†…å®¹: {final_prompt}")
            else:
                st.warning("æœªèƒ½è¯†åˆ«åˆ°è¯­éŸ³å†…å®¹")
            
            # Cleanup
            try:
                temp_audio_path.unlink()
            except:
                pass

    # Process Message
    if final_prompt:
        # User message
        with st.chat_message("user"):
            st.markdown(final_prompt)
        
        # AI Response
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            message_placeholder.markdown("Thinking...")
            
            # Call Jarvis
            response = st.session_state.jarvis.chat(final_prompt)
            
            message_placeholder.markdown(response)

